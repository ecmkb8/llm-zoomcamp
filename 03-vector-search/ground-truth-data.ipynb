{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import hashlib\n",
    "import dotenv\n",
    "from elasticsearch import Elasticsearch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from openai import OpenAI\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pickle\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../01-Intro\")\n",
    "import minsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prepare the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"documents.json\", 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)\n",
    "\n",
    "documents = []\n",
    "for course in docs_raw:\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_document_id(doc):\n",
    "\n",
    "    combined = f\"{doc['course']}-{doc['question']}-{doc['text'][:10]}\"\n",
    "    hash_object = hashlib.md5(combined.encode())\n",
    "    hash_hex = hash_object.hexdigest()\n",
    "    document_id = hash_hex[:8]\n",
    "\n",
    "    return document_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    doc['id'] = generate_document_id(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents-with-ids.json', 'wt') as f_out:\n",
    "    json.dump(documents, f_out, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You emulate a student taking our course.\n",
    "Formulate 5 questions this student might ask based on the FAQ record provided. The record should contain the answer to the questions, and the\n",
    "questions should be complete and not too short. If possible, use as few words as possible from the record.\n",
    "\n",
    "The record:\n",
    "section: {section}\n",
    "question: {question}\n",
    "answer: {text}\n",
    "\n",
    "Provide the output in parsable JSON without using code blocks:\n",
    "\n",
    "[\"question1\", \"question2\", \"question3\", \"question4\", \"question5\"]\n",
    "\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(doc, prompt_template):\n",
    "    \n",
    "    prompt = prompt_template.format(**doc)\n",
    "    \n",
    "    resp = ai_client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "    )\n",
    "    json_response = json.loads(resp.choices[0].message.content)\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('results.pkl', 'rb') as f_in:\n",
    "        results = pickle.load(f_in)\n",
    "except FileNotFoundError:\n",
    "    results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = defaultdict(list)\n",
    "for doc in documents:\n",
    "    ids[doc['id']].append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [00:00<00:00, 2195582.66it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    id = doc['id']\n",
    "    if id in results:\n",
    "        continue\n",
    "    try:\n",
    "        questions = doc['questions'] = generate_questions(doc, prompt_template)\n",
    "        results[id] = questions\n",
    "    except Exception as e:\n",
    "        with open('results.pkl', 'wb') as f_out:\n",
    "            pickle.dump(results, f_out)\n",
    "        continue\n",
    "\n",
    "with open('results.pkl', 'wb') as f_out:\n",
    "    pickle.dump(results, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.pkl', 'wb') as f_out:\n",
    "    pickle.dump(results, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_index = {doc['id']: doc for doc in documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = []\n",
    "for id, questions in results.items():\n",
    "    doc = doc_index[id]\n",
    "    for question in questions:\n",
    "        final_results.append((question, doc['course'], id))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ground-truth-data.csv', 'wt') as f_out:\n",
    "    writer = csv.writer(f_out)\n",
    "    writer.writerow(['question', 'course', 'document_id'])\n",
    "    writer.writerows(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'ad69993b5bed', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'uxoTwmPhSw2EfiNXPOhI9Q', 'version': {'number': '8.17.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': 'a091390de485bd4b127884f7e565c0cad59b10d2', 'build_date': '2025-02-28T10:07:26.089129809Z', 'build_snapshot': False, 'lucene_version': '9.12.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client = Elasticsearch(\"http://localhost:9200\")\n",
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"section\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"question\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"course\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"id\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)\n",
    "\n",
    "for doc in documents:\n",
    "    try:\n",
    "        es_client.index(index=index_name, document=doc)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_query(query: str, course: str):\n",
    "\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"text\", \"section\", \"question^3\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                    \"filter\": {\n",
    "                        \"term\": {\n",
    "                            \"course\": course\n",
    "                            }\n",
    "                        }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    results = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        results.append(hit['_source'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x31e32f620>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"text\", \"section\", \"question\"],\n",
    "    keyword_fields=[\"course\", \"id\"]\n",
    ")\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query, course):\n",
    "    boost = {'question':3, 'section':0.5}\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': course},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ground_truth = pd.read_csv('./ground-truth-data.csv')\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevance_logging(ground_truth: dict, search_method, ) -> list:\n",
    "    relevance_tracking = []\n",
    "\n",
    "    for query in tqdm(ground_truth):\n",
    "        id = query['document_id']\n",
    "        # if search_method.__name__ == 'es_query':\n",
    "        resp = search_method(query=query['question'], course=query['course'])\n",
    "        # else:\n",
    "        #     resp = search_method(query)\n",
    "        # print(resp)\n",
    "        result_relevance = [d['id'] == id for d in resp]\n",
    "        relevance_tracking.append(result_relevance)\n",
    "\n",
    "    return relevance_tracking\n",
    "\n",
    "\n",
    "def hit_rate(relevance_tracking: dict) -> float: \n",
    "\n",
    "    hits = sum(map(lambda x: True in x, relevance_tracking))\n",
    "    return hits/len(relevance_tracking)\n",
    "\n",
    "def mrr(relevance_tracking: dict) -> float:\n",
    "\n",
    "    n = len(relevance_tracking)\n",
    "    relevance_total = 0\n",
    "\n",
    "    for r in relevance_tracking:\n",
    "        try:\n",
    "            index = r.index(True) + 1\n",
    "            relevance_total += (1/index)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        \n",
    "    return relevance_total / n\n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4655/4655 [00:08<00:00, 568.04it/s]\n",
      "100%|██████████| 4655/4655 [00:18<00:00, 256.21it/s]\n"
     ]
    }
   ],
   "source": [
    "relevance_results_minsearch = relevance_logging(ground_truth=ground_truth, search_method=minsearch_search)\n",
    "relevance_results_elastic_search = relevance_logging(ground_truth=ground_truth, search_method=es_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7523093447905478, 0.612631578947369)\n",
      "(0.8021482277121375, 0.6812853562477629)\n"
     ]
    }
   ],
   "source": [
    "metrics_es = (hit_rate(relevance_results_elastic_search), mrr(relevance_results_elastic_search))\n",
    "metrics_min = (hit_rate(relevance_results_minsearch), mrr(relevance_results_minsearch))\n",
    "\n",
    "print(metrics_es)\n",
    "print(metrics_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "encoding = model.encode(\"Is it worth bothering?\")\n",
    "print(len(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"section\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"question\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"course\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"question_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            }\n",
    "\n",
    "       }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [01:32<00:00, 10.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    try:\n",
    "        doc['question_vector'] = model.encode(doc['question'])\n",
    "        doc['text_vector'] = model.encode(doc['text'])\n",
    "        doc['question_text_vector'] = model.encode(doc['question'] + ' ' + doc['text'])\n",
    "        es_client.index(index=index_name, document=doc)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search_term = model.encode(\"Can I enroll after the course has started?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn(field, vector, course):\n",
    "    \n",
    "    # vector_search_term = model.encode(query)\n",
    "    \n",
    "    knn = {\n",
    "            \"field\": field,\n",
    "            \"query_vector\": vector,\n",
    "            \"k\": 5,\n",
    "            \"num_candidates\": 10000,\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
    "        }\n",
    "\n",
    "    es_results = es_client.search(index=index_name, \n",
    "                        body=search_query)\n",
    "\n",
    "    result_docs = []\n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '7842b56a'},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'a482086d'},\n",
       " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What can I do before the course starts?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '63394d91'},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'c02e79ef'},\n",
       " {'text': \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Certificate - Can I follow the course in a self-paced mode and get a certificate?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'cb257ee5'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_search_knn('question_vector', vector_search_term, 'data-engineering-zoomcamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
